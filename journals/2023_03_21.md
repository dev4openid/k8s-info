- Fault-tolerance
- On-demand scalability
- Optimal resource usage
- Auto-discovery to automatically discover and communicate with each other
- Accessibility from the outside world
- Seamless updates/rollbacks without any downtime.
-
- Container Orchestrators
- [Amazon Elastic Container Service](https://aws.amazon.com/ecs/)]
	- Amazon Elastic Container Service (ECS) is a hosted service provided by [Amazon Web Services](https://aws.amazon.com/) (AWS) to run containers at scale on its infrastructure.
- [Azure Container Instances](https://azure.microsoft.com/en-us/products/container-instances/#overview)
	- Azure Container Instance (ACI) is a basic container orchestration service provided by [Microsoft Azure](https://azure.microsoft.com/en-us/).
- [Azure Service Fabric](https://azure.microsoft.com/en-us/products/service-fabric/)
  Azure Service Fabric is an open source container orchestrator provided by [Microsoft Azure](https://azure.microsoft.com/en-us/).
- [Kubernetes](https://kubernetes.io/)
	- Kubernetes is an open source orchestration tool, originally started by Google, today part of the [Cloud Native Computing Foundation](https://www.cncf.io/) (CNCF) project.
- [Marathon](https://mesosphere.github.io/marathon/)
	- Marathon is a framework to run containers at scale on [Apache Mesos](https://mesos.apache.org/) and [DC/OS](https://dcos.io/).
- [Nomad](https://www.nomadproject.io/)
	- Nomad is the container and workload orchestrator provided by [HashiCorp](https://www.hashicorp.com/).
	-
- [Docker Swarm](https://docs.docker.com/engine/swarm/)
	- Docker Swarm is a container orchestrator provided by [Docker, Inc](https://www.docker.com/). It is part of [Docker Engine](https://docs.docker.com/engine/).
-
- Look at https://www.edx.org/course/introduction-to-cloud-infrastructure-technologies
-
- **[Kubernetes website](https://kubernetes.io/),**
	- Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications".*
-
- **Borg**, or to lessons learned from it, are:
	- API servers
	- Pods
	- IP-per-Pod
	- Services
	- Labels
- **Kubernetes Features**
	- Automatic bin packing
	- Designed for extensibility
	- Self-healing
	- Horizontal scaling
	- Service discovery and load balancing
- **Additional features**
	- Automated rollouts and rollbacks
	- Secret and configuration management
	- Storage orchestration (mounts software-defined storage (SDS))
	- Batch execution
	- IPv4/IPv6 dual-stack
-
- **Popular graduated projects:**
- [Kubernetes](https://kubernetes.io/) container orchestrator
- [etcd](https://etcd.io/) distributed key-value store
- [CoreDNS](https://coredns.io/) DNS server
- [containerd](http://containerd.io/) container runtime
- [Envoy](https://www.envoyproxy.io/) cloud native proxy
- [Fluentd](http://www.fluentd.org/) for unified logging
- [Harbor](https://goharbor.io/) registry
- [Helm](https://www.helm.sh/) package management for Kubernetes
- [Linkerd](https://linkerd.io/) service mesh for Kubernetes
- [Open Policy Agent](https://www.openpolicyagent.org/) policy engine
- [Prometheus](https://prometheus.io/) monitoring system and time series DB
- [Rook](https://rook.io/) cloud native storage orchestrator for Kubernetes
  
  **Key incubating projects:**
- [argo](https://argoproj.github.io/) workflow engine for Kubernetes
- [Buildpacks.io](https://buildpacks.io/) builds application images
- [CRI-O](https://cri-o.io/) container runtime
- [Contour](https://projectcontour.io/) ingress controller for Kubernetes
- [gRPC](http://www.grpc.io/) for remote procedure call (RPC)
- [CNI](https://www.cni.dev/) for Linux containers networking
- [flux](https://fluxcd.io/) continuous delivery for Kubernetes
- [Knative](https://knative.dev/) serverless containers in Kubernetes
- [KubeVirt](https://kubevirt.io/) Kubernetes based Virtual Machine manager
- [Notary](https://github.com/theupdateframework/notary) for data security
- And many [more](https://www.cncf.io/projects/).
-
- One or more **control plane** nodes
- One or more **worker** nodes (optional, but recommended).
- ![Components of Kubernetes Architecture](https://courses.edx.org/asset-v1:LinuxFoundationX+LFS158x+1T2022+type@asset+block@TrainingImage.png)
- A control plane node runs the following essential control plane components and agents:
	- API Server
	- Scheduler
	- Controller Managers
	- Key-Value Data Store
	- In addition, the control plane node runs:
		- Container Runtime
		- Node Agent
		- Proxy
		- Optional add-ons for cluster-level monitoring and logging
-
- A worker node has the following components:
	- Container Runtime
	- Node Agent - kubelet
	- Proxy - kube-proxy
	- Add-ons for DNS, Dashboard user interface, cluster-level monitoring and logging
-
- # Networking Challenges
	- networking challenges:
	- Container-to-Container communication inside Pods
	- Pod-to-Pod communication on the same node and across cluster nodes
	- Service-to-Pod communication within the same namespace and across cluster namespaces
	- External-to-Service communication for clients to access applications in a cluster
	  
	  All these networking challenges must be addressed before deploying a Kubernetes cluster
- **Container-to-Container Communication Inside Pods**
	- isolated network space is referred to as a **network namespace**
	- Pod is started, a special infrastructure **Pause container** is initialized by the Container Runtime
- "**IP-per-Pod**" and ensures Pod-to-Pod communication
- **Pod-to-Pod Communication Across Nodes**
	- **localhost** - inside the Pod
	- Containers are integrated with the overall Kubernetes networking model through the use of the [Container Network Interface](https://github.com/containernetworking/cni) (CNI). CNI plugins are 3rd-party Software Defined Networking (SDN)
	- ![Container Network Interface (CNI)](https://courses.edx.org/asset-v1:LinuxFoundationX+LFS158x+1T2022+type@asset+block@Container_Network_Interface__CNI__Core_Plugins2023.png)**Container Network Interface (CNI) ****Core Plugins**
-
- **External-to-Pod Communication**
	- external accessibility through **Services**
	- complex encapsulations of network routing rule definitions stored in **iptables** on cluster nodes and implemented by **kube-proxy** agents
	- with the aid of **kube-proxy**, applications become accessible from outside the cluster over a virtual IP address and a dedicated port number
	-
	-
- # Kubernetes Configuration
- **All-in-One Single-Node Installation**
  In this setup, all the control plane and worker components are installed and running on a single-node. While it is useful for learning, development, and testing, it is not recommended for production purposes.
- **Single-Control Plane and Multi-Worker Installation**
  In this setup, we have a single-control plane node running a stacked etcd instance. Multiple worker nodes can be managed by the control plane node.
- **Single-Control Plane with Single-Node etcd, and Multi-Worker Installation**
  In this setup, we have a single-control plane node with an external etcd instance. Multiple worker nodes can be managed by the control plane node.
- **Multi-Control Plane and Multi-Worker Installation**
  In this setup, we have multiple control plane nodes configured for High-Availability (HA), with each control plane node running a stacked etcd instance. The etcd instances are also configured in an HA etcd cluster and multiple worker nodes can be managed by the HA control plane.
- **Multi-Control Plane with Multi-Node etcd, and Multi-Worker Installation**
  In this setup, we have multiple control plane nodes configured in HA mode, with each control plane node paired with an external etcd instance. The external etcd instances are also configured in an HA etcd cluster, and multiple worker nodes can be managed by the HA control plane. This is the most advanced cluster configuration recommended for production environments
-
# Infrastructure for Kubernetes Installation
- Kubernetes on bare metal, public cloud, private, or hybrid cloud?
- Which underlying OS should we use?
- Which networking solution (CNI) should we use?
-
# Installing Local Learning Clusters
- [Minikube](https://minikube.sigs.k8s.io/docs/) 
  Single- and multi-node local Kubernetes cluster, recommended for a learning environment deployed on a single host.
- [Kind](https://kind.sigs.k8s.io/) 
  Multi-node Kubernetes cluster deployed in Docker containers acting as Kubernetes nodes, recommended for a learning environment.
- [Docker Desktop](https://www.docker.com/products/docker-desktop) 
  Including a local Kubernetes cluster for Docker users.
- [MicroK8s](https://microk8s.io/) 
  Local and cloud Kubernetes cluster for developers and production, from Canonical.
- [K3S](https://k3s.io/) 
  Lightweight Kubernetes cluster for local, cloud, edge, IoT deployments, originally from Rancher, currently a CNCF project.
# Production Clusters from Certified Solutions Providers
# Kubernetes on Windows
- as a [supported](https://kubernetes.io/docs/setup/production-environment/windows/intro-windows-in-kubernetes/) production ready operating system only for worker nodes of a Kubernetes cluster
-
- # Minikube
- isolation software --driver
- #of cluster nodes, sizes in terms of CPU, memory, and disk space
- Hypervisor can be, in order of preference (on a Linux host): docker, kvm2, podman, vmware, and virtualbox
	- On Linux [VirtualBox](https://www.virtualbox.org/wiki/Downloads), [KVM2](https://www.linux-kvm.org/page/Main_Page), and [QEMU](https://www.qemu.org/) hypervisors, or [Docker](https://docs.docker.com/engine/install/) and [Podman](https://podman.io/getting-started/installation.html) runtimes
	- On macOS [VirtualBox](https://www.virtualbox.org/wiki/Downloads), [HyperKit](https://github.com/moby/hyperkit), [VMware Fusion](http://www.vmware.com/products/fusion.html), [Parallels](https://www.parallels.com/), and [QEMU](https://www.qemu.org/) hypervisors, or [Docker](https://docs.docker.com/desktop/mac/install/) runtime
	- On Windows [VirtualBox](https://www.virtualbox.org/wiki/Downloads), [Hyper-V](https://docs.microsoft.com/en-us/virtualization/hyper-v-on-windows/quick-start/enable-hyper-v), [VMware Workstation](https://www.vmware.com/in/products/workstation-pro/workstation-pro-evaluation.html), and [QEMU](https://www.qemu.org/) hypervisors, or [Docker](https://docs.docker.com/desktop/windows/install/) runtime
	- **NOTE:** Minikube supports a ***[--driver=none](https://minikube.sigs.k8s.io/docs/drivers/none/)*** (on Linux) option that runs the Kubernetes components bare-metal, directly on the host OS and not inside a VM. With this option a Docker installation is required and a Linux OS on the local workstation, but no hypervisor installation. This driver is recommended for advanced users.
-
- # get creds
- After minikube start
	- (e.g. minikube start -n 3    OR  minikube start --driver=kvm -n 3 --container-runtime=containerd \
	    --cni=calico -p minibox  *Note: the -p name !*)
	- TOKEN=$(kubectl describe secret -n kube-system $(kubectl get secrets -n kube-system | rg default | cut -f1 -d ' ') | grep -E '^token' | cut -f2 -d ':' | tr -d '\t' | tr -d ' ')
	- echo $TOKEN
	- APISERVER=$(kubectl config view | rg  https |  cut -f 2- -d ":" | tr -d ' ')
	- echo $APISERVER
	- curl $APISERVER --header "Authorization: Bearer $TOKEN" --insecure
	- curl $APISERVER/apis/app/v1 --header "Authorization: Bearer $TOKEN" --insecure
- (*there is a problem with script above*)
-
- # Obj