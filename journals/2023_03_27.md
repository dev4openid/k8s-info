- # kubectl
- **CRUD**
	- kubctl create deployment [name]
	- kubctl edit deployment [name]    (editing config live in memory)
	- kubctl delete deployment [name]
- **Status of components**
	- kubctl get nodes | pod | services | replicaset | deployment
- **Debugging pods**
	- kubctl logs [pod name]
	- kubctl exec -it [pod name] -- bin/bash
	- kubctl describe pod [pod name]
- **Config file**
	- kubctl apply -f [file name]
	- kubctl delete -f [file name]
- # YAML config for K8s
- **3 parts of config file**
	- 1. metadata
	  2. specification  (deployment then lower level for pod)
	  3. status - automatically generated so not part of yaml definition file  (actual vs. desired state)
	  Contingent as to which "spec" (kind: Deployment OR Service)is being created **spec** structure is different! 
	                           (Note for Deployment then apiVersion: apps/v1 whereas Service is apiVersion: v1)
	- Layers of Abstraction
		- **Deployment** manages a ...
		- **ReplicaSet** manages a  ...
		- **Pod** is an abstraction of ...
		- **Container**
	- **Deployment**
		- ```
		  apiVersion: apps/v1
		  kind: Deployment
		  metadata:
		    name: nginx-deployment
		    labels:
		      app: nginx
		  spec:         # Deployment
		    replicas: 1
		    selector:
		      matchLabels: 
		        app: nginx
		    template:
		      metadata:
		        labels:
		          app: nginx
		      spec:             # pod
		        containers:
		        - name: nginx
		          image: nginx:1.20.2
		          ports:
		          - containerPort: 80
		  ```
			- Note the Deployment vs Pod ---> the recursive of "metadata" [3-6] and "spec" [13-15] data!
			- **Blueprint** [16-21]
- # Labels & Selectors
- **Service**
	- ```
	  apiVersion: v1
	  kind: Service
	  metadata:
	    name: nginx-service
	  spec:
	    selector:
	    	app: nginx
	      ports: ....
	  ```
		- The  Service selector in deployment [6 & 15] matches service  [7] - so the can be connected!