- [[Stateful Sets (STS)]]
- [[Notes: Secrets and ConfigMaps]]
- ## Probes
- check for:
	- liveness
	- readiness
	- startup
- ![Probes options/strategies](/home/briandanks/Pictures/Screenshots/Screenshot from 2023-07-04 14-25-02.png){:height 300, :width 650}
- Probes options/strategies
- ![Probe tolerances](/home/briandanks/Pictures/Screenshots/Screenshot from 2023-07-04 14-28-16.png){:height 270, :width 650}
- Liveness probe tolerances
- ![Workflow for probes](/home/briandanks/Pictures/Screenshots/Screenshot from 2023-07-04 14-47-12.png){:height 332, :width 650}
- Workflow for probes
- ==Notes:==
	- Ideal frequency of timings
	- Lightweight tests conducted / minimal impact
	- Correct Restart policy
	- Keep an eye on Probes regularly
- ## Limits
- CPU is NOT the issue (it will throttle as necessary)
- Mem IS the issue. Mem management is determined by the requests per POD irrespective of Actual Usage or Limits defined
- Over alloc of POD mem leads to evaluation of all Requests, then Limits followed by QoS determination (1. BestEffort (no resources defined), 2. Burstable (Request < Limits) , 3. Guaranteed Where Request = Limits are equal size).  Lookout for application memory leaks leading to OOM, or spike in demand - increase in resource intensive workloads, or heavy resource usage by container/pods on same node - all can lead to OOM.
- ==Note:==
	- Kind: ResourceQuota define the limits applicable to the *Namespace*
	- Kind: LimitRange defines limits for a *Pod* or *Container*
	- Otherwise the requests are tailored as content within a Pod or Container
- Strategies for OOM remedy/diagnostics
	- kubectl get pods - check status and restart count
	- kubectl logs for a specific container
	- kubectl top - reflects biggest resource capacity and utilisation
	-
- ## Affinity
- ![Affinity methods](/home/briandanks/Pictures/Screenshots/Screenshot from 2023-07-04 20-03-00.png)
- Affinity methods
- ## Autoscalers
- HPA (Horizonatal Pod Autoscaler  - Horiz.Scaling)
- VPA (Vertical Pod Autoscaler - Scale UP)
- CA (Cluster Autoscaler - add new/reduce # of Nodes)
- ### HPA
	- ![How HPA calculates number of Pods](/home/briandanks/Pictures/Screenshots/Screenshot from 2023-07-04 20-12-06.png)
	- How HPA calculates number of Pods
- ### VPA
	- ![Vertical Pod Autoscaler](/home/briandanks/Pictures/Screenshots/Screenshot from 2023-07-04 20-24-17.png)
	- Vertical Pod Autoscaler
	- To install
		- ```cmake
		  git clone https://github.com/kubernetes/autoscaler.git
		  cd autoscaler
		  ./vertical-pod-autoscaler/hack/vpa-up.sh   # note therer are other functions in vpa-down.sh / etc.
		  cd ..	# in this example
		  kubectl apply -f vpa.yaml # vpa in this example
		  ```
- ### CA
- ![Cluster Autoscaler](/home/briandanks/Pictures/Screenshots/Screenshot from 2023-07-04 20-40-41.png)
- Cluster Autoscaler
-