- # Stateful Service (STS)
- each pod will connect to it's own PVC and PV
- but service is NOT LoadBalancer but None (i.e. a Headless Service) ---> clusterIP: None
- all pods are ordered pods with sticky ID (to ensure consistency and allow slaves/master to find each other for replication)
- only master is read/write - slaves are read only
- if the ordered sequence of pods has a problem with any node the the process stops and no further pods are initiated (sequence dependency in the order)
- e.g.
	- mongodb-0.mongodb-svc.default.svc.cluster.local:27017   (coreDNS reference)
		- ==Note:==
			- mongodb-0 is the pod name plus a -increment (e.g. -0 and so forth)
			- mongodb-svc is the service name
			- default is the minikube default or could be any namespace
- ![Deployment vs. Statefulset](/home/briandanks/Pictures/Screenshots/Screenshot from 2023-07-04 10-51-40.png)
- Deployment vs. Statefulset
- The pods are now sequence BUT need to set up replicaset to ensure data is consistent from master to slaves
	- `kubectl exec -it mongo-0 -- mongo`
	- then in mongo at prompt execute
		- ```
		  rs.initiate(
		  	{
		      _id:"rs0",	# rs0 is the replicaset name
		        members: [
		          {_id:0, host : "mongo-0.mongo.default.svc.cluster.local:27017"},
		          {_id:0, host : "mongo-1.mongo.default.svc.cluster.local:27017"},
		          {_id:0, host : "mongo-2.mongo.default.svc.cluster.local:27017"}
		        ]
		      }
		  )
		  ```
		- then exit and reenter, look for `rs.status()`and check the prompt is rs0:PRIMARY (this can be checked for rs1:SECONDARY or rs2 :SECONDARY)
		- goto `kubectl exec -it mongo-1 -- mongo` and execute `rs.slaveOk()`to invoke the sync of data from master to slaves
- ## Secrets and ConfigMaps
- config data:
	- passing arguments
	- config files
	- env variables
- configMap is limited to 1 Mb
- elements of configMap (=env variables==) are not updated in the pods when the updated configMap is applied - the pods need to be deleted and recreated (be careful)
- ## Probes
- check for:
	- liveness
	- readiness
	- startup
- ![Probes options/strategies](/home/briandanks/Pictures/Screenshots/Screenshot from 2023-07-04 14-25-02.png)
- Probes options/strategies
- ![Probe tolerances](/home/briandanks/Pictures/Screenshots/Screenshot from 2023-07-04 14-28-16.png)
- Liveness probe tolerances
- ![Workflow for probes](/home/briandanks/Pictures/Screenshots/Screenshot from 2023-07-04 14-47-12.png)
- Workflow for probes
- ==Notes:==
	- Ideal frequency of timings
	- Lightweight tests conducted / minimal impact
	- Correct Restart policy
	- Keep an eye on Probes regularly
- ## Limits
- CPU is NOT the issue (it will throttle as necessary)
- Mem IS the issue. Mem management is determined by the requests per POD irrespective of Actual Usage or Limits defined
- Over alloc of POD mem leads to evaluation of all Requests, then Limits followed by QoS determination (1. BestEffort (no resources defined), 2. Burstable (Request < Limits) , 3. Guaranteed Where Request = Limits are equal size).  Lookout for application memory leaks leading to OOM, or spike in demand - increase in resource intensive workloads, or heavy resource usage by container/pods on same node - all can lead to OOM.
- ==Note:==
	- Kind: ResourceQuota define the limits applicable to the *Namespace*
	- Kind: LimitRange defines limits for a *Pod* or *Container*
	- Otherwise the requests are tailored as content within a Pod or Container
- Strategies for OOM remedy/diagnostics
	- kubectl get pods - check status and restart count
	- kubectl logs for a specific container
	- kubectl top - reflects biggest resource capacity and utilisation
	-
- ## Affinity
- ![Affinity methods](/home/briandanks/Pictures/Screenshots/Screenshot from 2023-07-04 20-03-00.png)
- Affinity methods
- ## Autoscalers
- HPA (Horizonatal Pod Autoscaler  - Horiz.Scaling)
- VPA (Vertical Pod Autoscaler - Scale UP)
- CA (add new/reduce # of Nodes)